{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "## Imports and directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2\n",
    "import os,shutil\n",
    "import random\n",
    "import time\n",
    "\n",
    "def charge_msg(msg):\n",
    "    print(msg, end=\"\\r\")\n",
    "    time.sleep(0)\n",
    "\n",
    "pure_dataset_path = \"pure_dataset\"\n",
    "small_dataset_path = \"small_dataset\"\n",
    "normalized_dataset_path = \"same_size_dataset\"\n",
    "dataset_path = \"dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate max image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dataset_max_size():\n",
    "    max_height = -1\n",
    "    max_width = -1\n",
    "    gray_channels = -1\n",
    "    color_channels = -1\n",
    "    i = 1\n",
    "    for path_image in glob.glob(pure_dataset_path + \"/*.jpg\"):\n",
    "        charge_msg(\"Number of images processed: \" + str(i))\n",
    "        i = i + 1\n",
    "        image_name = path_image.split('\\\\')[1] # with .jpg at the end!\n",
    "        image = cv2.imread(path_image,1)\n",
    "\n",
    "        height, width, channels = image.shape\n",
    "\n",
    "        if height > max_height:\n",
    "            max_height = height\n",
    "        if width > max_width:\n",
    "            max_width = width\n",
    "        if channels > gray_channels:\n",
    "            gray_channels = channels\n",
    "        if channels > color_channels:\n",
    "            color_channels = channels\n",
    "        \n",
    "    return max_height, max_width\n",
    "\n",
    "#max_height, max_width = calculate_dataset_max_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_image_size():\n",
    "    average_width = 0\n",
    "    average_height = 0\n",
    "    for index, image_path in enumerate(glob.glob(pure_dataset_path + \"/*.jpg\"), start = 1):\n",
    "        image_name = image_path.split('\\\\')[1]\n",
    "        image = cv2.imread(image_path,1)\n",
    "\n",
    "        image_height, image_width, c = image.shape\n",
    "\n",
    "        average_width += image_width\n",
    "        average_height += image_height\n",
    "\n",
    "        charge_msg(\"Processed images:\" + str(index) + \" - Average width: \" + str(average_width/index) + \" - Average height: \" + str(average_height/index))\n",
    "\n",
    "    print(\"\")\n",
    "    average_width = average_width / index\n",
    "    average_height = average_height / index\n",
    "    print(\"Average width: \" + str(average_width))\n",
    "    print(\"Average height: \" + str(average_height))\n",
    "    return average_width, average_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed images:12750 - Average width: 977.1720784313726 - Average height: 795.5912156862745\n",
      "Average width: 977.1720784313726\n",
      "Average height: 795.5912156862745\n",
      "Width limit: 1177.1720784313725\n",
      "Height limit: 995.5912156862745\n"
     ]
    }
   ],
   "source": [
    "width_limit,height_limit = average_image_size()\n",
    "\n",
    "width_limit += 200\n",
    "height_limit += 200\n",
    "\n",
    "print(\"Width limit: \" + str(width_limit))\n",
    "print(\"Height limit: \" + str(height_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_small_dataset():\n",
    "    number_small_images = 0\n",
    "    for path_image in glob.glob(pure_dataset_path + \"/*.jpg\"):\n",
    "        image_name = path_image.split('\\\\')[1] # with .jpg at the end!\n",
    "        image = cv2.imread(path_image,1)\n",
    "\n",
    "        image_height, image_width, c = image.shape\n",
    "\n",
    "        if image_height <= height_limit and image_width <= width_limit:\n",
    "            number_small_images += 1\n",
    "            cv2.imwrite( small_dataset + '/' + image_name, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path_image in glob.glob(small_dataset_path + \"/*.jpg\"):\n",
    "    image_name = path_image.split('\\\\')[1] # with .jpg at the end!\n",
    "    normalize_image(path_image, image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print(max_height, max_width)\n",
    "# Crear matriz X,Y\n",
    "new_image = np.full([max_height, max_width, 3],255)\n",
    "print(new_image)\n",
    "# Copiar imagen en matriz (con canales)\n",
    "\"\"\"\n",
    "#for c in range(0, 3):\n",
    "#    [y_offset:y_offset+s_img.shape[0], x_offset:x_offset+s_img.shape[1]] = s_img\n",
    "\"\"\"\n",
    "old_image = cv2.imread(\"pure_dataset/000a045a0715d64d.jpg\",1)\n",
    "for c in range(0, 3):\n",
    "    new_image[0:old_image.shape[0], 0:old_image.shape[1],c] = old_image[0:old_image.shape[0], 0:old_image.shape[1],c]\n",
    "# Pasar matriz a imagen\n",
    "img = Image.fromarray(new_image, 'RGB')\n",
    "img.save(\"111111aaaaaa.jpg\", \"JPEG\")1\n",
    "# https://stackoverflow.com/questions/14063070/overlay-a-smaller-image-on-a-larger-image-python-opencv\n",
    "\"\"\"\n",
    "def normalize_image(image_path, image_name):\n",
    "    image = cv2.imread(image_path,1)\n",
    "\n",
    "    image_height, image_width, c = image.shape\n",
    "\n",
    "    normalized_image = cv2.copyMakeBorder(\n",
    "        image,\n",
    "        top = 0,\n",
    "        bottom = int(height_limit - image_height),\n",
    "        left = 0,\n",
    "        right = int(width_limit - image_width),\n",
    "        borderType = cv2.BORDER_CONSTANT,\n",
    "        value = [0, 0, 0]\n",
    "    )\n",
    "\n",
    "    cv2.imwrite( normalized_dataset_path + '/' + image_name, normalized_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clear folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our pure dataset is on pure_dataset (Oh! Is so pure!).\n",
      "Our dataset will be on dataset. \n",
      "The dataset folder already exist. We will delete it and the images...\n",
      "Images and folder deleted\n",
      "Folder: dataset has been created\n",
      "Folder: dataset/train has been created\n",
      "Folder: dataset/train/color has been created\n",
      "Folder: dataset/train/color has been created\n",
      "Folder: dataset/validation has been created\n",
      "Folder: dataset/validation/color has been created\n",
      "Folder: dataset/validation/color has been created\n",
      "Folder: dataset/test has been created\n",
      "Folder: dataset/test/color has been created\n",
      "Folder: dataset/test/color has been created\n"
     ]
    }
   ],
   "source": [
    "print(\"Our pure dataset is on \" + pure_dataset_path + \" (Oh! Is so pure!).\")\n",
    "print(\"Our dataset will be on \" + dataset_path + \". \")\n",
    "\n",
    "if os.path.isdir(dataset_path):\n",
    "    print(\"The dataset folder already exist. We will delete it and the images...\")\n",
    "    shutil.rmtree(dataset_path)\n",
    "    print(\"Images and folder deleted\")\n",
    "os.makedirs(dataset_path)\n",
    "print(\"Folder: \" + dataset_path + \" has been created\")\n",
    "\n",
    "os.makedirs(dataset_path + \"/train\")\n",
    "print(\"Folder: \" + dataset_path + \"/train has been created\")\n",
    "os.makedirs(dataset_path + \"/train/color\")\n",
    "print(\"Folder: \" + dataset_path + \"/train/color has been created\")\n",
    "os.makedirs(dataset_path + \"/train/gray\")\n",
    "print(\"Folder: \" + dataset_path + \"/train/color has been created\")\n",
    "\n",
    "os.makedirs(dataset_path + \"/validation\")\n",
    "print(\"Folder: \" + dataset_path + \"/validation has been created\")\n",
    "os.makedirs(dataset_path + \"/validation/color\")\n",
    "print(\"Folder: \" + dataset_path + \"/validation/color has been created\")\n",
    "os.makedirs(dataset_path + \"/validation/gray\")\n",
    "print(\"Folder: \" + dataset_path + \"/validation/color has been created\")\n",
    "\n",
    "os.makedirs(dataset_path + \"/test\")\n",
    "print(\"Folder: \" + dataset_path + \"/test has been created\")\n",
    "os.makedirs(dataset_path + \"/test/color\")\n",
    "print(\"Folder: \" + dataset_path + \"/test/color has been created\")\n",
    "os.makedirs(dataset_path + \"/test/gray\")\n",
    "print(\"Folder: \" + dataset_path + \"/test/color has been created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images... Image: 9715\n",
      "\n",
      "\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "number_images_procesed = 0\n",
    "MAX_NUMBER_TRAIN = 7000\n",
    "MAX_NUMBER_VALIDATION = 5000\n",
    "MAX_NUMBER_TEST = 750\n",
    "folder = \"/train\"\n",
    "for path_image in glob.glob(normalized_dataset_path + \"/*.jpg\"):\n",
    "    image_name = path_image.split('\\\\')[1] # with .jpg at the end!\n",
    "    image = cv2.imread(path_image,1)\n",
    "    gray = cv2.cvtColor(cv2.imread(path_image), cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if(number_images_procesed > MAX_NUMBER_TRAIN):\n",
    "        if(number_images_procesed > (MAX_NUMBER_TRAIN + MAX_NUMBER_VALIDATION)):\n",
    "            folder = \"/test\"\n",
    "        else:\n",
    "            folder = \"/validation\"\n",
    "    cv2.imwrite(dataset_path + folder + \"/color/\" + str(image_name), image)\n",
    "    cv2.imwrite(dataset_path + folder + \"/gray/\" + str(image_name), gray)\n",
    "    \n",
    "    number_images_procesed = number_images_procesed + 1\n",
    "    charge_msg(\"Processing images... Image: \" + str(number_images_procesed))\n",
    "print(\"\")\n",
    "print(\"\\n\")\n",
    "print(\"All done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
